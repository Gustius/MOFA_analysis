#   W.mean <- W.mean + 0.5*y[n]*X[n,]
#   # W.mean <- W.mean + (y[n]-0.5)*X[n,]
# }
# W.covInv <- chol2inv(chol(W.cov))
# W.mean <- W.covInv %*% W.mean
#
# Update expectations
# W <- W.mean
# WW <- tcrossprod(W.mean) + W.cov
## Update alpha ##
#   a_n = a_0 + D/2
#   b_n = b_0 + 0.5*E[w^{t}*w]
# Update parameters
alpha.a <- opts$prior.b_alpha + D/2
# alpha.b <- opts$prior.b_alpha + sum(diag(WW))/2
alpha.b <- opts$prior.b_alpha + 0.5*sum(diag((W.mean%*%t(W.mean) + W.covInv)))[1] # CHECK IF THIS IS CORRECT
# Update expectations
alpha <- alpha.a/alpha.b
alpha.logE <- digamma(alpha.a) - log(alpha.b)
## Update variational parameter ##
# (Zeta_new)^2 = x_n^{t} * (w.Cov + w.Mean*w.Mean^{t})*x_n
# zeta <- sqrt( t(X) %*% (covW + outer(W)) %*% X )
zeta <- rep(NA,N)
for (n in 1:N) {
zeta[n] <- sqrt( X[n,,drop=F] %*% (W.covInv + W.mean%*%t(W.mean)) %*% t(X[n,,drop=F]) )
}
###############################
## Calculate the lower bound ##
###############################
# Likelihood term (with the local bound)
# E_w[ln h(w,Zeta)] = 0.5*(w.Mean^t %*% Sn^{-1} %*% w.Mean) - D/2 + 0.5*a_n/b_n*(w.Mean^t%*%w_n + tr(w.Cov)) + \sum_{n=1}^{N} (ln[sigmoid(zeta_n)] - zeta_n/2 + lambda(zeta_n)*zeta_n^2)
lb.lik <- 0.5*(t(W.mean)%*%W.cov%*%W.mean) - D/2 - 0.5*alpha*(t(W.mean)%*%W.mean+sum(diag(W.covInv)))
for (n in 1:N) {
lb.lik <- lb.lik + log(sigmoid(zeta[n])) - zeta[n]/2 + lambda(zeta[n])*zeta[n]**2
}
lb <- lb.lik
# W term:
# E_{w,alpha}[ln p(W)] - E_{w,alpha}[ln q(W)]
# E_{w,alpha}[ln p(W|alpha)] = -(D/2)*ln(2pi) + (D/2)*(psi(a_n) - ln[b_n]) - 0.5*(a_n/b_n)*(w.Mean*w.Mean^t + tr(w.Cov))
# E_{w,alpha}[ln q(W)] = -(D*2)*(1+ln(2pi)) - 0.5*ln(|w.Cov|)
lb.pw <- -0.5*D*log(2*pi) + 0.5*D*alpha.logE - 0.5*alpha*(t(W.mean)%*%W.mean + sum(diag(W.covInv)))
lb.qw <- -0.5*D*(1+log(2*pi)) - 0.5*sum(log(det(W.covInv)))
lb <- lb + lb.pw - lb.qw
# Alpha term:
# E[ln p(alpha)] - E[ln q(alpha)]
# E[ln p(alpha)] = -ln[Gamma(a0)] + a0*ln[b0] + (a0-1)*(psi(a_n) - ln[b_n]) - b0*(a_n/b_n)
# E[ln q(alpha)] = -ln[Gamma(a_n)] + (a_n-1)*psi(a_n) + ln[b_n] - a_n
lb.palpha <- -lgamma(opts$prior.a_alpha) + opts$prior.a_alpha*log(opts$prior.b_alpha) + (opts$prior.a_alpha-1)*alpha.logE - opts$prior.b_alpha*alpha
lb.qalpha <- -lgamma(alpha.a) + (alpha.a-1)*alpha.logE + log(alpha.b) - alpha.a
lb <- lb + lb.palpha - lb.qalpha
# Store the error and lower bound
lbound[iter] <- lb
lbound_terms[iter,] = c(lik=lb.lik, w=lb.pw-lb.qw, alpha=lb.palpha-lb.qalpha)
# Print monitoring statistics
cat(paste("Iteration:",iter," lbound:",lb,"\n"))
cat(sprintf("lik=%0.02f, W=%0.02f, alpha=%0.02f\n", lbound_terms[iter,"lik"], lbound_terms[iter,"W"], lbound_terms[iter,"alpha"]))
# Converge if the relative change in the lower bound is small enough
if (iter>1) {
diff <- lbound[iter] - lbound[iter-1]
if(abs(diff) < opts$iter.crit) {
# Remove empty values from the diagnostics
lbound_terms <- lbound_terms[complete.cases(lbound_terms),]
lbound <- lbound[!is.na(lbound)]
break
}
}
}
return(list(W=W, alpha=alpha, zeta=zeta))
}
model <- foo(y, X, opts)
ypred <- sigmoid(X %*% model$W)
head(ypred)
head(y)
W.covInv <- solve(chol(W.cov))
View(W.covInv)
###########################################
## Variational logistic regression model ##
###########################################
###########
## Model ##
###########
# Likelihood:
#   p(y|X,w) = \prod_{n}^{N} sigmoid(w*X_n)^{y_n} * (1-sigmoid(w*X_n))^{1-y_{n}}
# Marginal likelihood:
#   p(y) = \int \int \prod_{n=1}^{N} p(y_n|w,X_n)p(w)p(alpha) dw dalpha
# Priors:
#   p(w) = Normal(w | 0, alpha^{-1})
#   p(alpha) = Gamma(alpha|a0,b0)
###########################
## Variational inference ##
###########################
## Variational lower bound ##
# Without approximation:
#   ln P(y|X) >= L(Q) = \int \int q(w,alpha) ln[\frac{p(Y|x,w,)p(w|alpha)p(alpha)}{Q(w,alpha)}] dw dalpha
# With approximation:
# ??? WHY NO Y OR X IN THE APPROXIMATION ???
#                L(Q) = \int \int q(w,alpha) ln[\frac{h(w,zeta)p(w|alpha)p(alpha)}{Q(w,alpha)}] dw dalpha
## Variational distribution:
# q(w,alpha) = q(w) q(alpha)
## Local Variational bound introduced by Jaakola and Jordan, 2000 ##
# The data likelihood does not admit a conugate prior in the exponential family and will be approximated by the use of:
#   sigmoid(z) >= sigmoid(zeta) * exp{ (z-zeta)/2 - lambda(zeta)*(z^2-zeta^2) }
#      where lambda(zeta) = 0.5*zeta * (sigmoid(zeta) - 0.5)
# Rewriting the likelihood and plugging in the lower bound (equations 10.148-10.151 in Bishop) we obtain:
#   p(y_n|w,x_n) = exp{w*x_n*y_n} * sigmoid(-w*x_n)
#              >= exp{w*x_n*y_n} * sigmoid(zeta_n) * exp{ -(w*x_n+zeta_n)/2 - lambda(zeta)*((w*x_n)^2 - zeta^2) }
# which is a tight lower bound on the sigmoid, with one additional parameter, zeta, per datum.
# Applying this bound, the data log-likelihood is lower-bounded by:
#  log p(y_n|w,x_n) >= h(w,zeta_n) = 0.5*w^{t}*y_n*x_n - w^t*(lambda(zeta_n)*x_n*x_n^t)*w + ln[sigmoid(zeta_n)] - zeta_n/2 + lambda(zeta_n)*zeta_n^2
# Cince the logarithm is monotonically icnreasing we can write ln A >= ln B if A >= B:
#   ln[p(y_n,X,w)] >= ln[p(w)] + \sum_n^N { ln[sigmoid(zeta_n)] + w^t*x_n*t_n - (w^t*x_n + zeta_n)/2 - lambda(zeta_n)*((w*x_n)^2 - zeta_n^2) }
## Updates ##
# q(w): N( w | w.Mean, w.Cov)
#   w.Cov^{-1} = E[alpha]*I + 2*\sum_{n}^{N} { lambda(zeta_n)*x_n*x_n^{t} }
#   w.Mean = w.Cov * \sum_{n}^{N} { y_n*x_n/2 }
# q(alpha) = Gamma( alpha | a_n, b_n )
#   a_n = a_0 + D/2
#   b_n = b_0 + 0.5*E[w^{t}*w]
## Optimization of variational parametrers ##
# We maximise the variational lower bound with respect to zeta_n
# (Zeta_new)^2 = x_n^{t} * (w.Cov + w.Mean*w.Mean^{t})*x_n
## Predictive distribution ##
# In order to get the predictive density, the posterior P(w|D) is approximated by the variational posterior Q(w),
# and the sigmoid is lower-bounded by the corresponding bound:
# p(Y=1|x,D) = \int p(Y=1|x,w) * p(w|D) dW
#            ~ \int p(Y=1|x,w) * Q(w) dW
#            >= \int (...)
# The integral is solved by noting that the lower bound is exponentially quadratic in n N w, such that the Gaussian can be completed:
# (...)
## Variational Lower bound L(Q,Zeta) ##
# Likelihood term (with the local bound):
# E_w[ln h(w,Zeta)] = \sum_n^N { ln[sigmoid(zeta_n)] + E[w^t]*x_n*y_n - 0.5*(E[w^t]*x_n + zeta_n)) - \lambda(zeta_n)*(E[(w^t*x_n)^2] - zeta_n^2)  }
#                   = 0.5*(w.Mean^t %*% Sn^{-1} %*% w.Mean) - D/2 + 0.5*a_n/b_n*(w.Mean^t%*%w_n + tr(w.Cov)) + \sum_{n=1}^{N} (ln[sigmoid(zeta_n)] - zeta_n/2 + lambda(zeta_n)*zeta_n^2)
# W term
# E_{w,alpha}[ln p(W|alpha)] = -(D/2)*ln(2pi) + (D/2)*E[ln(|alpha|)] - 0.5*E[w{t}]*E[(alpha*I)]*E[w]
#                            = -(D/2)*ln(2pi) + (D/2)*(psi(a_n) - ln[b_n]) - 0.5*(a_n/b_n)*(w.Mean*w.Mean^t + tr(w.Cov))
# E_{w,alpha}[ln q(W)] = -(D*2)*(1+ln(2pi)) - 0.5*ln(|w.Cov|)
# alpha term:
# E_{alpha}[ln p(alpha)] = -ln[Gamma(a0)] + a0*ln[b0] + (a0-1)*E[ln(alpha)] - b0*E[alpha]
#                        = -ln[Gamma(a0)] + a0*ln[b0] + (a0-1)*(psi(a_n) - ln[b_n]) - b0*(a_n/b_n)
# E_{alpha}[ln q(alpha)] = -ln[Gamma(a_n)] + (a_n-1)*psi(a_n) + ln[b_n] - a_n
## Expectations ##
# E[alpha] = a_n/b_n
# E_w[w * w^{t}] = w.Mean * w.Mean^t + w.Cov
# E_w[w^t * w] = tr(w.Cov) * w.Mean^t*w.Mean
####################
## Implementation ##
####################
## Define functions ##
sigmoid <- function(x) 1/(1+exp(-x))
lambda <- function(zeta) { 0.5*zeta * (sigmoid(zeta)-0.5) }
## Define options ##
opts <- list()
# Maximum number of iterations
opts$iter.max <- 100
# Convergence criteria
opts$iter.crit <- 0.01
# Initialisations
opts$init.W <- 0
opts$init.alpha <- 1
opts$init.zeta <- 1
# Hyperparameters
opts$prior.a_alpha <- 1e-14
opts$prior.b_alpha <- 1e-14
## Load data ##
# mydata <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
# write.table(mydata, "/Users/ricard/logistic_data.csv", row.names = F, col.names = T, quote = F)
mydata <- read.table("/Users/ricard/logistic_data.csv", header=T)
y <- as.matrix(mydata[,1])
X <- scale(as.matrix(mydata[,2:ncol(mydata)]), center=T, scale=T)
foo <- function(y, X, opts) {
# Y: (N,) binary vector
# X: (N,K) matrix
# opts: list
#   iter.max (1000 by default)
#   iter.crit (10^-6 by default)
#   init.W (0 by default)
#   init.alpha (not sure what initialisation)
#   prior.a_alpha (1e-14 by default)
#   prior.b_alpha (1e-14 by default)
# Store dimensionalities of data sets
N <- nrow(X)
D <- ncol(X)
# Sanity checks
stopifnot(length(y)==N)
stopifnot(all(y%in%c(0,1)))
##########################
## Initialize the model ##
##########################
# Monitor training
lbound_terms <- matrix(nrow=opts$iter.max, ncol=3)    # For storing the lower bound terms
colnames(lbound_terms) <- c("lik","W","alpha")
lbound <- rep(NA,opts$iter.max)        # For storing the lower bounds
# Initialise weights
W <- rep(opts$init.W,D)
# Initialise alpha
alpha <- opts$init.alpha
# Initialise zeta
zeta <- rep(opts$init.zeta,N)
# The main loop
for (iter in 1:opts$iter.max) {
#####################
## Perform updates ##
#####################
## Update W ##
# q(w): N( w | w.Mean, w.Cov)
# Update parameters
#   w.Cov^{-1} = E[alpha]*I + 2*\sum_{n}^{N} { lambda(zeta_n)*x_n*x_n^{t} }
#   w.Mean = w.Cov * \sum_{n}^{N} { 0.5*y_n*x_n }
#  (Q) THERE IS A DISCREPANCY HERE WITH BISHOP: w.Mean = w.Cov * \sum_{n}^{N} { (y_n-0.5)*x_n }
W.cov <- alpha*diag(D)
W.mean <- matrix(0,nr=D,nc=1)
for (n in 1:N) {
W.cov <- W.cov + 2*lambda(zeta[n])*(X[n,]%o%X[n,])
W.mean <- W.mean + 0.5*y[n]*X[n,]
# W.mean <- W.mean + (y[n]-0.5)*X[n,]
}
# W.covInv <- chol2inv(chol(W.cov))
W.covInv <- solve(chol(W.cov))
W.mean <- W.covInv %*% W.mean
# Update expectations
W <- W.mean
WW <- tcrossprod(W.mean) + W.cov
## Update alpha ##
# alpha.a = a_0 + D/2
# alpha.b = b_0 + 0.5*E[w^{t}*w]
# Update parameters
alpha.a <- opts$prior.b_alpha + D/2
alpha.b <- opts$prior.b_alpha + sum(diag(WW))/2
# alpha.b <- opts$prior.b_alpha + 0.5*sum(diag((W.mean%*%t(W.mean) + W.covInv)))[1] # CHECK IF THIS IS CORRECT
# Update expectations
alpha <- alpha.a/alpha.b
alpha.logE <- digamma(alpha.a) - log(alpha.b)
## Update variational parameter ##
# (Zeta_new)^2 = x_n^{t} * (w.Cov + w.Mean*w.Mean^{t})*x_n
# zeta <- sqrt( t(X) %*% (covW + outer(W)) %*% X )
zeta <- rep(NA,N)
for (n in 1:N) {
zeta[n] <- sqrt( X[n,,drop=F] %*% (W.covInv + W.mean%*%t(W.mean)) %*% t(X[n,,drop=F]) )
}
###############################
## Calculate the lower bound ##
###############################
# Likelihood term (with the local bound)
# E_w[ln h(w,Zeta)] = 0.5*(w.Mean^t %*% Sn^{-1} %*% w.Mean) - D/2 + 0.5*a_n/b_n*(w.Mean^t%*%w_n + tr(w.Cov)) + \sum_{n=1}^{N} (ln[sigmoid(zeta_n)] - zeta_n/2 + lambda(zeta_n)*zeta_n^2)
lb.lik <- 0.5*(t(W.mean)%*%W.cov%*%W.mean) - D/2 - 0.5*alpha*(t(W.mean)%*%W.mean+sum(diag(W.covInv)))
for (n in 1:N) {
lb.lik <- lb.lik + log(sigmoid(zeta[n])) - zeta[n]/2 + lambda(zeta[n])*zeta[n]**2
}
lb <- lb.lik
# W term:
# E_{w,alpha}[ln p(W)] - E_{w,alpha}[ln q(W)]
# E_{w,alpha}[ln p(W|alpha)] = -(D/2)*ln(2pi) + (D/2)*(psi(a_n) - ln[b_n]) - 0.5*(a_n/b_n)*(w.Mean*w.Mean^t + tr(w.Cov))
# E_{w,alpha}[ln q(W)] = -(D*2)*(1+ln(2pi)) - 0.5*ln(|w.Cov|)
lb.pw <- -0.5*D*log(2*pi) + 0.5*D*alpha.logE - 0.5*alpha*(t(W.mean)%*%W.mean + sum(diag(W.covInv)))
lb.qw <- -0.5*D*(1+log(2*pi)) - 0.5*sum(log(det(W.covInv)))
lb <- lb + lb.pw - lb.qw
# Alpha term:
# E[ln p(alpha)] - E[ln q(alpha)]
# E[ln p(alpha)] = -ln[Gamma(a0)] + a0*ln[b0] + (a0-1)*(psi(a_n) - ln[b_n]) - b0*(a_n/b_n)
# E[ln q(alpha)] = -ln[Gamma(a_n)] + (a_n-1)*psi(a_n) + ln[b_n] - a_n
lb.palpha <- -lgamma(opts$prior.a_alpha) + opts$prior.a_alpha*log(opts$prior.b_alpha) + (opts$prior.a_alpha-1)*alpha.logE - opts$prior.b_alpha*alpha
lb.qalpha <- -lgamma(alpha.a) + (alpha.a-1)*alpha.logE + log(alpha.b) - alpha.a
lb <- lb + lb.palpha - lb.qalpha
# Store the error and lower bound
lbound[iter] <- lb
lbound_terms[iter,] = c(lik=lb.lik, w=lb.pw-lb.qw, alpha=lb.palpha-lb.qalpha)
# Print monitoring statistics
cat(paste("Iteration:",iter," lbound:",lb,"\n"))
cat(sprintf("lik=%0.02f, W=%0.02f, alpha=%0.02f\n", lbound_terms[iter,"lik"], lbound_terms[iter,"W"], lbound_terms[iter,"alpha"]))
# Converge if the relative change in the lower bound is small enough
if (iter>1) {
diff <- lbound[iter] - lbound[iter-1]
if(abs(diff) < opts$iter.crit) {
# Remove empty values from the diagnostics
lbound_terms <- lbound_terms[complete.cases(lbound_terms),]
lbound <- lbound[!is.na(lbound)]
break
}
}
}
return(list(W=W, alpha=alpha, zeta=zeta))
}
model <- foo(y, X, opts)
ypred <- sigmoid(X %*% model$W)
head(ypred)
head(y)
W
W
model$W
X
model$w
model$W
View(mydata)
###########################################
## Variational logistic regression model ##
###########################################
###########
## Model ##
###########
# Likelihood:
#   p(y|X,w) = \prod_{n}^{N} sigmoid(w*X_n)^{y_n} * (1-sigmoid(w*X_n))^{1-y_{n}}
# Marginal likelihood:
#   p(y) = \int \int \prod_{n=1}^{N} p(y_n|w,X_n)p(w)p(alpha) dw dalpha
# Priors:
#   p(w) = Normal(w | 0, alpha^{-1})
#   p(alpha) = Gamma(alpha|a0,b0)
###########################
## Variational inference ##
###########################
## Variational lower bound ##
# Without approximation:
#   ln P(y|X) >= L(Q) = \int \int q(w,alpha) ln[\frac{p(Y|x,w,)p(w|alpha)p(alpha)}{Q(w,alpha)}] dw dalpha
# With approximation:
# ??? WHY NO Y OR X IN THE APPROXIMATION ???
#                L(Q) = \int \int q(w,alpha) ln[\frac{h(w,zeta)p(w|alpha)p(alpha)}{Q(w,alpha)}] dw dalpha
## Variational distribution:
# q(w,alpha) = q(w) q(alpha)
## Local Variational bound introduced by Jaakola and Jordan, 2000 ##
# The data likelihood does not admit a conugate prior in the exponential family and will be approximated by the use of:
#   sigmoid(z) >= sigmoid(zeta) * exp{ (z-zeta)/2 - lambda(zeta)*(z^2-zeta^2) }
#      where lambda(zeta) = 0.5*zeta * (sigmoid(zeta) - 0.5)
# Rewriting the likelihood and plugging in the lower bound (equations 10.148-10.151 in Bishop) we obtain:
#   p(y_n|w,x_n) = exp{w*x_n*y_n} * sigmoid(-w*x_n)
#              >= exp{w*x_n*y_n} * sigmoid(zeta_n) * exp{ -(w*x_n+zeta_n)/2 - lambda(zeta)*((w*x_n)^2 - zeta^2) }
# which is a tight lower bound on the sigmoid, with one additional parameter, zeta, per datum.
# Applying this bound, the data log-likelihood is lower-bounded by:
#  log p(y_n|w,x_n) >= h(w,zeta_n) = 0.5*w^{t}*y_n*x_n - w^t*(lambda(zeta_n)*x_n*x_n^t)*w + ln[sigmoid(zeta_n)] - zeta_n/2 + lambda(zeta_n)*zeta_n^2
# Cince the logarithm is monotonically icnreasing we can write ln A >= ln B if A >= B:
#   ln[p(y_n,X,w)] >= ln[p(w)] + \sum_n^N { ln[sigmoid(zeta_n)] + w^t*x_n*t_n - (w^t*x_n + zeta_n)/2 - lambda(zeta_n)*((w*x_n)^2 - zeta_n^2) }
## Updates ##
# q(w): N( w | w.Mean, w.Cov)
#   w.Cov^{-1} = E[alpha]*I + 2*\sum_{n}^{N} { lambda(zeta_n)*x_n*x_n^{t} }
#   w.Mean = w.Cov * \sum_{n}^{N} { y_n*x_n/2 }
# q(alpha) = Gamma( alpha | a_n, b_n )
#   a_n = a_0 + D/2
#   b_n = b_0 + 0.5*E[w^{t}*w]
## Optimization of variational parametrers ##
# We maximise the variational lower bound with respect to zeta_n
# (Zeta_new)^2 = x_n^{t} * (w.Cov + w.Mean*w.Mean^{t})*x_n
## Predictive distribution ##
# In order to get the predictive density, the posterior P(w|D) is approximated by the variational posterior Q(w),
# and the sigmoid is lower-bounded by the corresponding bound:
# p(Y=1|x,D) = \int p(Y=1|x,w) * p(w|D) dW
#            ~ \int p(Y=1|x,w) * Q(w) dW
#            >= \int (...)
# The integral is solved by noting that the lower bound is exponentially quadratic in n N w, such that the Gaussian can be completed:
# (...)
## Variational Lower bound L(Q,Zeta) ##
# Likelihood term (with the local bound):
# E_w[ln h(w,Zeta)] = \sum_n^N { ln[sigmoid(zeta_n)] + E[w^t]*x_n*y_n - 0.5*(E[w^t]*x_n + zeta_n)) - \lambda(zeta_n)*(E[(w^t*x_n)^2] - zeta_n^2)  }
#                   = 0.5*(w.Mean^t %*% Sn^{-1} %*% w.Mean) - D/2 + 0.5*a_n/b_n*(w.Mean^t%*%w_n + tr(w.Cov)) + \sum_{n=1}^{N} (ln[sigmoid(zeta_n)] - zeta_n/2 + lambda(zeta_n)*zeta_n^2)
# W term
# E_{w,alpha}[ln p(W|alpha)] = -(D/2)*ln(2pi) + (D/2)*E[ln(|alpha|)] - 0.5*E[w{t}]*E[(alpha*I)]*E[w]
#                            = -(D/2)*ln(2pi) + (D/2)*(psi(a_n) - ln[b_n]) - 0.5*(a_n/b_n)*(w.Mean*w.Mean^t + tr(w.Cov))
# E_{w,alpha}[ln q(W)] = -(D*2)*(1+ln(2pi)) - 0.5*ln(|w.Cov|)
# alpha term:
# E_{alpha}[ln p(alpha)] = -ln[Gamma(a0)] + a0*ln[b0] + (a0-1)*E[ln(alpha)] - b0*E[alpha]
#                        = -ln[Gamma(a0)] + a0*ln[b0] + (a0-1)*(psi(a_n) - ln[b_n]) - b0*(a_n/b_n)
# E_{alpha}[ln q(alpha)] = -ln[Gamma(a_n)] + (a_n-1)*psi(a_n) + ln[b_n] - a_n
## Expectations ##
# E[alpha] = a_n/b_n
# E_w[w * w^{t}] = w.Mean * w.Mean^t + w.Cov
# E_w[w^t * w] = tr(w.Cov) * w.Mean^t*w.Mean
####################
## Implementation ##
####################
## Define functions ##
sigmoid <- function(x) 1/(1+exp(-x))
lambda <- function(zeta) { 0.5*zeta * (sigmoid(zeta)-0.5) }
## Define options ##
opts <- list()
# Maximum number of iterations
opts$iter.max <- 100
# Convergence criteria
opts$iter.crit <- 0.01
# Initialisations
opts$init.W <- 0
opts$init.alpha <- 1
opts$init.zeta <- 1
# Hyperparameters
opts$prior.a_alpha <- 1e-14
opts$prior.b_alpha <- 1e-14
## Load data ##
# mydata <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
# write.table(mydata, "/Users/ricard/logistic_data.csv", row.names = F, col.names = T, quote = F)
mydata <- read.table("/Users/ricard/logistic_data.csv", header=T)
y <- as.matrix(mydata[,1])
X <- scale(as.matrix(mydata[,2:ncol(mydata)]), center=T, scale=T)
foo <- function(y, X, opts) {
# Y: (N,) binary vector
# X: (N,K) matrix
# opts: list
#   iter.max (1000 by default)
#   iter.crit (10^-6 by default)
#   init.W (0 by default)
#   init.alpha (not sure what initialisation)
#   prior.a_alpha (1e-14 by default)
#   prior.b_alpha (1e-14 by default)
# Store dimensionalities of data sets
N <- nrow(X)
D <- ncol(X)
# Sanity checks
stopifnot(length(y)==N)
stopifnot(all(y%in%c(0,1)))
##########################
## Initialize the model ##
##########################
# Monitor training
lbound_terms <- matrix(nrow=opts$iter.max, ncol=3)    # For storing the lower bound terms
colnames(lbound_terms) <- c("lik","W","alpha")
lbound <- rep(NA,opts$iter.max)        # For storing the lower bounds
# Initialise weights
W <- rep(opts$init.W,D)
# Initialise alpha
alpha <- opts$init.alpha
# Initialise zeta
zeta <- rep(opts$init.zeta,N)
# The main loop
for (iter in 1:opts$iter.max) {
#####################
## Perform updates ##
#####################
## Update W ##
# q(w): N( w | w.Mean, w.Cov)
# Update parameters
#   w.Cov^{-1} = E[alpha]*I + 2*\sum_{n}^{N} { lambda(zeta_n)*x_n*x_n^{t} }
#   w.Mean = w.Cov * \sum_{n}^{N} { 0.5*y_n*x_n }
#  (Q) THERE IS A DISCREPANCY HERE WITH BISHOP: w.Mean = w.Cov * \sum_{n}^{N} { (y_n-0.5)*x_n }
W.cov <- alpha*diag(D)
W.mean <- matrix(0,nr=D,nc=1)
for (n in 1:N) {
W.cov <- W.cov + 2*lambda(zeta[n])*(X[n,]%o%X[n,])
W.mean <- W.mean + 0.5*y[n]*X[n,]
# W.mean <- W.mean + (y[n]-0.5)*X[n,]
}
# W.covInv <- chol2inv(chol(W.cov))
W.covInv <- solve(chol(W.cov))
W.mean <- W.covInv %*% W.mean
# Update expectations
W <- W.mean
WW <- tcrossprod(W.mean) + W.cov
## Update alpha ##
# alpha.a = a_0 + D/2
# alpha.b = b_0 + 0.5*E[w^{t}*w]
# Update parameters
alpha.a <- opts$prior.b_alpha + D/2
alpha.b <- opts$prior.b_alpha + sum(diag(WW))/2
# alpha.b <- opts$prior.b_alpha + 0.5*sum(diag((W.mean%*%t(W.mean) + W.covInv)))[1] # CHECK IF THIS IS CORRECT
# Update expectations
alpha <- alpha.a/alpha.b
alpha.logE <- digamma(alpha.a) - log(alpha.b)
## Update variational parameter ##
# (Zeta_new)^2 = x_n^{t} * (w.Cov + w.Mean*w.Mean^{t})*x_n
# zeta <- sqrt( t(X) %*% (covW + outer(W)) %*% X )
zeta <- rep(NA,N)
for (n in 1:N) {
zeta[n] <- sqrt( X[n,,drop=F] %*% (W.covInv + W.mean%*%t(W.mean)) %*% t(X[n,,drop=F]) )
}
###############################
## Calculate the lower bound ##
###############################
# Likelihood term (with the local bound)
# E_w[ln h(w,Zeta)] = 0.5*(w.Mean^t %*% Sn^{-1} %*% w.Mean) - D/2 + 0.5*a_n/b_n*(w.Mean^t%*%w_n + tr(w.Cov)) + \sum_{n=1}^{N} (ln[sigmoid(zeta_n)] - zeta_n/2 + lambda(zeta_n)*zeta_n^2)
lb.lik <- 0.5*(t(W.mean)%*%W.cov%*%W.mean) - D/2 - 0.5*alpha*(t(W.mean)%*%W.mean+sum(diag(W.covInv)))
for (n in 1:N) {
lb.lik <- lb.lik + log(sigmoid(zeta[n])) - zeta[n]/2 + lambda(zeta[n])*zeta[n]**2
}
lb <- lb.lik
# W term:
# E_{w,alpha}[ln p(W)] - E_{w,alpha}[ln q(W)]
# E_{w,alpha}[ln p(W|alpha)] = -(D/2)*ln(2pi) + (D/2)*(psi(a_n) - ln[b_n]) - 0.5*(a_n/b_n)*(w.Mean*w.Mean^t + tr(w.Cov))
# E_{w,alpha}[ln q(W)] = -(D*2)*(1+ln(2pi)) - 0.5*ln(|w.Cov|)
lb.pw <- -0.5*D*log(2*pi) + 0.5*D*alpha.logE - 0.5*alpha*(t(W.mean)%*%W.mean + sum(diag(W.covInv)))
lb.qw <- -0.5*D*(1+log(2*pi)) - 0.5*sum(log(det(W.covInv)))
lb <- lb + lb.pw - lb.qw
# Alpha term:
# E[ln p(alpha)] - E[ln q(alpha)]
# E[ln p(alpha)] = -ln[Gamma(a0)] + a0*ln[b0] + (a0-1)*(psi(a_n) - ln[b_n]) - b0*(a_n/b_n)
# E[ln q(alpha)] = -ln[Gamma(a_n)] + (a_n-1)*psi(a_n) + ln[b_n] - a_n
lb.palpha <- -lgamma(opts$prior.a_alpha) + opts$prior.a_alpha*log(opts$prior.b_alpha) + (opts$prior.a_alpha-1)*alpha.logE - opts$prior.b_alpha*alpha
lb.qalpha <- -lgamma(alpha.a) + (alpha.a-1)*alpha.logE + log(alpha.b) - alpha.a
lb <- lb + lb.palpha - lb.qalpha
# Store the error and lower bound
lbound[iter] <- lb
lbound_terms[iter,] = c(lik=lb.lik, w=lb.pw-lb.qw, alpha=lb.palpha-lb.qalpha)
# Print monitoring statistics
cat(paste("Iteration:",iter," lbound:",lb,"\n"))
cat(sprintf("lik=%0.02f, W=%0.02f, alpha=%0.02f\n", lbound_terms[iter,"lik"], lbound_terms[iter,"W"], lbound_terms[iter,"alpha"]))
# Converge if the relative change in the lower bound is small enough
if (iter>1) {
diff <- lbound[iter] - lbound[iter-1]
if(abs(diff) < opts$iter.crit) {
# Remove empty values from the diagnostics
lbound_terms <- lbound_terms[complete.cases(lbound_terms),]
lbound <- lbound[!is.na(lbound)]
break
}
}
}
return(list(W=W, alpha=alpha, zeta=zeta))
}
model <- foo(y, X, opts)
head(ypred)
ypred <- sigmoid(X %*% model$W)
head(ypred)
head(y)
head(ypred,=10)
head(ypred,n=10)
head(y,n=10)
head(ypred,n=10)
head(y,n=10)
